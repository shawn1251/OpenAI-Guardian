services:
  nginx:
    image: nginx:alpine
    volumes:
      #- ./nginx.conf:/etc/nginx/conf.d/default.conf
      - ./nginx.without_SSL.conf:/etc/nginx/conf.d/default.conf
      #- ./certs:/etc/nginx/certs 
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - guardian
      - mitmproxy

  guardian:
    # x86 cpu image
    build:
      context: ./vllm # need .git folder for setuptools-scm
      #dockerfile: ./Dockerfile.cpu
      dockerfile: ./Dockerfile.arm #for apple silicon
      shm_size: '4g'
    image: vllm-guardian
    environment:
      - VLLM_CPU_KVCACHE_SPACE=10 # you can increase this if you have more memory
    command: --model /model --dtype=float16
    #command: --model /model --disable-frontend-multiprocessing
    ports:
      - "8000:8000"
    volumes:
      - ./model:/model
  mitmproxy:
    image: my_mitmproxy
    build: ./mitmproxy
    ports:
      - "8080:8080"
    command: mitmdump -s /code/intercept_openai.py --mode reverse:https://api.openai.com
    volumes:
      - ./mitmproxy/code/intercept_openai.py:/code/intercept_openai.py
      - ~/.mitmproxy:/home/mitmproxy/.mitmproxy